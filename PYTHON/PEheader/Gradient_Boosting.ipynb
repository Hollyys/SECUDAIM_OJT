{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "70b0124d-32e0-418e-8534-32f344649a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pefile\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "742bf34e-5334-4266-a253-1139dc61f188",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entropy(data):\n",
    "    if len(data) == 0:\n",
    "        return 0.0\n",
    "    occurences = array.array('L', [0]*256)\n",
    "    for x in data:\n",
    "        occurences[x if isinstance(x, int) else ord(x)] += 1\n",
    "    entropy = 0\n",
    "    for x in occurences:\n",
    "        if x:\n",
    "            p_x = float(x) / len(data)\n",
    "            entropy -= p_x*math.log(p_x, 2)\n",
    "    return entropy\n",
    "\n",
    "def get_resources(pe):\n",
    "    \"\"\"Extract resources :\n",
    "    [entropy, size]\"\"\"\n",
    "    resources = []\n",
    "    if hasattr(pe, 'DIRECTORY_ENTRY_RESOURCE'):\n",
    "        try:\n",
    "            for resource_type in pe.DIRECTORY_ENTRY_RESOURCE.entries:\n",
    "                if hasattr(resource_type, 'directory'):\n",
    "                    for resource_id in resource_type.directory.entries:\n",
    "                        if hasattr(resource_id, 'directory'):\n",
    "                            for resource_lang in resource_id.directory.entries:\n",
    "                                data = pe.get_data(resource_lang.data.struct.OffsetToData, resource_lang.data.struct.Size)\n",
    "                                size = resource_lang.data.struct.Size\n",
    "                                entropy = get_entropy(data)\n",
    "\n",
    "                                resources.append([entropy, size])\n",
    "        except Exception as e:\n",
    "            return resources\n",
    "    return resources\n",
    "\n",
    "\n",
    "def get_version_info(pe):\n",
    "    \"\"\"Return version infos\"\"\"\n",
    "    res = {}\n",
    "    for fileinfo in pe.FileInfo:\n",
    "        if fileinfo.Key == 'StringFileInfo':\n",
    "            for st in fileinfo.StringTable:\n",
    "                for entry in st.entries.items():\n",
    "                    res[entry[0]] = entry[1]\n",
    "        if fileinfo.Key == 'VarFileInfo':\n",
    "            for var in fileinfo.Var:\n",
    "                res[var.entry.items()[0][0]] = var.entry.items()[0][1]\n",
    "    if hasattr(pe, 'VS_FIXEDFILEINFO'):\n",
    "        res['flags'] = pe.VS_FIXEDFILEINFO.FileFlags\n",
    "        res['os'] = pe.VS_FIXEDFILEINFO.FileOS\n",
    "        res['type'] = pe.VS_FIXEDFILEINFO.FileType\n",
    "        res['file_version'] = pe.VS_FIXEDFILEINFO.FileVersionLS\n",
    "        res['product_version'] = pe.VS_FIXEDFILEINFO.ProductVersionLS\n",
    "        res['signature'] = pe.VS_FIXEDFILEINFO.Signature\n",
    "        res['struct_version'] = pe.VS_FIXEDFILEINFO.StrucVersion\n",
    "    return res\n",
    "\n",
    "def extract_infos(fpath=None, already_pe=None, inference=None):\n",
    "    res = {}\n",
    "\n",
    "    try:\n",
    "        if fpath != None:\n",
    "            pe = pefile.PE(fpath)\n",
    "        else:\n",
    "            pe = already_pe[1]\n",
    "    except FileNotFoundError as e:\n",
    "        print(f\"File not found: {fpath}\")\n",
    "    except pefile.PEFormatError as e:\n",
    "        print(f\"PEFormatError: {fpath} does not appear to ba a PE file.\")\n",
    "        print(\"Error : \", e)\n",
    "        return\n",
    "\n",
    "    # if fpath!=None and inference==None:\n",
    "    #     res['md5'] = file_to_md5(fpath)\n",
    "    # elif already_pe!=None:\n",
    "    #     res['md5'] = already_pe[0]\n",
    "\n",
    "    res['Machine'] = pe.FILE_HEADER.Machine\n",
    "    res['SizeOfOptionalHeader'] = pe.FILE_HEADER.SizeOfOptionalHeader\n",
    "    res['Characteristics'] = pe.FILE_HEADER.Characteristics\n",
    "    res['MajorLinkerVersion'] = pe.OPTIONAL_HEADER.MajorLinkerVersion\n",
    "    res['MinorLinkerVersion'] = pe.OPTIONAL_HEADER.MinorLinkerVersion\n",
    "    res['SizeOfCode'] = pe.OPTIONAL_HEADER.SizeOfCode\n",
    "    res['SizeOfInitializedData'] = pe.OPTIONAL_HEADER.SizeOfInitializedData\n",
    "    res['SizeOfUninitializedData'] = pe.OPTIONAL_HEADER.SizeOfUninitializedData\n",
    "    res['AddressOfEntryPoint'] = pe.OPTIONAL_HEADER.AddressOfEntryPoint\n",
    "    res['BaseOfCode'] = pe.OPTIONAL_HEADER.BaseOfCode\n",
    "    try:\n",
    "        res['BaseOfData'] = pe.OPTIONAL_HEADER.BaseOfData\n",
    "    except AttributeError:\n",
    "        res['BaseOfData'] = 0\n",
    "    res['ImageBase'] = pe.OPTIONAL_HEADER.ImageBase\n",
    "    res['SectionAlignment'] = pe.OPTIONAL_HEADER.SectionAlignment\n",
    "    res['FileAlignment'] = pe.OPTIONAL_HEADER.FileAlignment\n",
    "    res['MajorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MajorOperatingSystemVersion\n",
    "    res['MinorOperatingSystemVersion'] = pe.OPTIONAL_HEADER.MinorOperatingSystemVersion\n",
    "    res['MajorImageVersion'] = pe.OPTIONAL_HEADER.MajorImageVersion\n",
    "    res['MinorImageVersion'] = pe.OPTIONAL_HEADER.MinorImageVersion\n",
    "    res['MajorSubsystemVersion'] = pe.OPTIONAL_HEADER.MajorSubsystemVersion\n",
    "    res['MinorSubsystemVersion'] = pe.OPTIONAL_HEADER.MinorSubsystemVersion\n",
    "    res['SizeOfImage'] = pe.OPTIONAL_HEADER.SizeOfImage\n",
    "    res['SizeOfHeaders'] = pe.OPTIONAL_HEADER.SizeOfHeaders\n",
    "    res['CheckSum'] = pe.OPTIONAL_HEADER.CheckSum\n",
    "    res['Subsystem'] = pe.OPTIONAL_HEADER.Subsystem\n",
    "    res['DllCharacteristics'] = pe.OPTIONAL_HEADER.DllCharacteristics\n",
    "    res['SizeOfStackReserve'] = pe.OPTIONAL_HEADER.SizeOfStackReserve\n",
    "    res['SizeOfStackCommit'] = pe.OPTIONAL_HEADER.SizeOfStackCommit\n",
    "    res['SizeOfHeapReserve'] = pe.OPTIONAL_HEADER.SizeOfHeapReserve\n",
    "    res['SizeOfHeapCommit'] = pe.OPTIONAL_HEADER.SizeOfHeapCommit\n",
    "    res['LoaderFlags'] = pe.OPTIONAL_HEADER.LoaderFlags\n",
    "    res['NumberOfRvaAndSizes'] = pe.OPTIONAL_HEADER.NumberOfRvaAndSizes\n",
    "\n",
    "       # Sections\n",
    "    res['SectionsNb'] = len(pe.sections)\n",
    "    entropy = list(map(lambda x:x.get_entropy(), pe.sections))\n",
    "    res['SectionsMeanEntropy'] = sum(entropy)/float(len(entropy))\n",
    "    res['SectionsMinEntropy'] = min(entropy)\n",
    "    res['SectionsMaxEntropy'] = max(entropy)\n",
    "    raw_sizes = list(map(lambda x:x.SizeOfRawData, pe.sections))\n",
    "    res['SectionsMeanRawsize'] = sum(raw_sizes)/float(len(raw_sizes))\n",
    "    res['SectionsMinRawsize'] = min(raw_sizes)\n",
    "    res['SectionsMaxRawsize'] = max(raw_sizes)\n",
    "    virtual_sizes = list(map(lambda x:x.Misc_VirtualSize, pe.sections))\n",
    "    res['SectionsMeanVirtualsize'] = sum(virtual_sizes)/float(len(virtual_sizes))\n",
    "    res['SectionsMinVirtualsize'] = min(virtual_sizes)\n",
    "    res['SectionMaxVirtualsize'] = max(virtual_sizes)\n",
    "    \n",
    "        #Imports\n",
    "    try:\n",
    "        res['ImportsNbDLL'] = len(pe.DIRECTORY_ENTRY_IMPORT)\n",
    "        imports = sum([x.imports for x in pe.DIRECTORY_ENTRY_IMPORT], [])\n",
    "        res['ImportsNb'] = len(imports)\n",
    "        res['ImportsNbOrdinal'] = len(list(filter(lambda x:x.name is None, imports)))\n",
    "    except AttributeError:\n",
    "        res['ImportsNbDLL'] = 0\n",
    "        res['ImportsNb'] = 0\n",
    "        res['ImportsNbOrdinal'] = 0\n",
    "\n",
    "    #Exports\n",
    "    try:\n",
    "        res['ExportNb'] = len(pe.DIRECTORY_ENTRY_EXPORT.symbols)\n",
    "    except AttributeError:\n",
    "        # No export\n",
    "        res['ExportNb'] = 0\n",
    "    #Resources\n",
    "    resources= get_resources(pe)\n",
    "    res['ResourcesNb'] = len(resources)\n",
    "\n",
    "    if len(resources)> 0:\n",
    "        entropy = list(map(lambda x:x[0], resources))\n",
    "        res['ResourcesMeanEntropy'] = sum(entropy)/float(len(entropy))\n",
    "        res['ResourcesMinEntropy'] = min(entropy)\n",
    "        res['ResourcesMaxEntropy'] = max(entropy)\n",
    "        sizes = list(map(lambda x:x[1], resources))\n",
    "        res['ResourcesMeanSize'] = sum(sizes)/float(len(sizes))\n",
    "        res['ResourcesMinSize'] = min(sizes)\n",
    "        res['ResourcesMaxSize'] = max(sizes)\n",
    "    else:\n",
    "        res['ResourcesNb'] = 0\n",
    "        res['ResourcesMeanEntropy'] = 0\n",
    "        res['ResourcesMinEntropy'] = 0\n",
    "        res['ResourcesMaxEntropy'] = 0\n",
    "        res['ResourcesMeanSize'] = 0\n",
    "        res['ResourcesMinSize'] = 0\n",
    "        res['ResourcesMaxSize'] = 0\n",
    "\n",
    "    # Load configuration size\n",
    "    try:\n",
    "        res['LoadConfigurationSize'] = pe.DIRECTORY_ENTRY_LOAD_CONFIG.struct.Size\n",
    "    except AttributeError:\n",
    "        res['LoadConfigurationSize'] = 0\n",
    "\n",
    "\n",
    "    # Version configuration size\n",
    "    try:\n",
    "        version_infos = get_version_info(pe)\n",
    "        res['VersionInformationSize'] = len(version_infos.keys())\n",
    "    except AttributeError:\n",
    "        res['VersionInformationSize'] = 0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "bd67e13b-b08c-4fd4-9701-6f6b30e02d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = extract_infos(fpath='/home/crossrunway/jupy/SECUDAIM_OJT/PYTHON/PEheader/exeFiles/DoublyLinkedListHashTable.exe', already_pe=None, inference=None)\n",
    "df2 = extract_infos(fpath='/home/crossrunway/jupy/SECUDAIM_OJT/PYTHON/PEheader/exeFiles/linkedlist_test.exe', already_pe=None, inference=None)\n",
    "df3 = extract_infos(fpath='/home/crossrunway/jupy/SECUDAIM_OJT/PYTHON/PEheader/exeFiles/initialC.exe', already_pe=None, inference=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "993123e7-cc0f-47b2-8e96-92febfcedb96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully, shape: (138047, 57)\n"
     ]
    }
   ],
   "source": [
    "# Load the CSV file with hash and features\n",
    "data = pd.read_csv('/home/crossrunway/jupy/SECUDAIM_OJT/PYTHON/PEheader/preprocessed_data.csv', sep='|')\n",
    "\n",
    "# Verify data loading\n",
    "print(\"Data loaded successfully, shape:\", data.shape)\n",
    "\n",
    "# Assume 'Label' is the column indicating malware status (1 for malware, 0 for benign)\n",
    "X = data.drop('label', axis=1)  # Features\n",
    "y = data['label']  # Target\n",
    "\n",
    "X = X.drop('Name', axis=1)\n",
    "X = X.drop('md5', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c83fa750-d5bc-44f9-89b5-b178353b1bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9945671858022456\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      8360\n",
      "           1       1.00      1.00      1.00     19250\n",
      "\n",
      "    accuracy                           0.99     27610\n",
      "   macro avg       0.99      0.99      0.99     27610\n",
      "weighted avg       0.99      0.99      0.99     27610\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_malware_model.joblib']"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgboost = xgb.XGBClassifier(n_estimators=30, eval_metric='logloss', random_state=42)\n",
    "xgboost.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "y_pred = xgboost.predict(X_test)\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Save the trained model\n",
    "joblib.dump(xgboost, 'xgboost_malware_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "40e95ba7-7fb2-4b46-b54b-e6b0ac313801",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The executable is classified as malware.\n"
     ]
    }
   ],
   "source": [
    "# Load the model for prediction\n",
    "xgboost = joblib.load('xgboost_malware_model.joblib')\n",
    "\n",
    "# Extract features from a specific executable file\n",
    "features_dict = df3\n",
    "\n",
    "# Convert the dictionary to a DataFrame with a single sample\n",
    "features_df = pd.DataFrame([features_dict])\n",
    "\n",
    "# Predict using the model\n",
    "prediction = xgboost.predict(features_df)\n",
    "\n",
    "# Output the result\n",
    "if prediction[0] == 1:\n",
    "    print(\"The executable is classified as malware.\")\n",
    "else:\n",
    "    print(\"The executable is classified as benign.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "7d55b99e-77e8-4f02-be0f-a7a5a37ec660",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n",
      "Best Parameters: {'colsample_bytree': 0.9, 'gamma': 0.1, 'learning_rate': 0.2, 'max_depth': 5, 'n_estimators': 200, 'subsample': 0.9}\n",
      "Accuracy: 0.9950560495481627\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     16564\n",
      "           1       1.00      1.00      1.00     38655\n",
      "\n",
      "    accuracy                           1.00     55219\n",
      "   macro avg       0.99      0.99      0.99     55219\n",
      "weighted avg       1.00      1.00      1.00     55219\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['xgboost_malware_model_optimized.joblib']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 4, 5],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Initialize and train the XGBoost model\n",
    "xgboost = xgb.XGBClassifier(eval_metric='logloss', random_state=42)\n",
    "grid_search = GridSearchCV(estimator=xgboost, param_grid=param_grid, scoring='accuracy', cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "joblib.dump(best_model, 'xgboost_malware_model_optimized.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "0998bdd5-61c5-4fe3-b5b5-144d75216f45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The executable is classified as malware.\n"
     ]
    }
   ],
   "source": [
    "# Load the model for prediction\n",
    "best_model = joblib.load('xgboost_malware_model.joblib')\n",
    "\n",
    "# Extract features from a specific executable file\n",
    "features_dict = df\n",
    "\n",
    "# Convert the dictionary to a DataFrame with a single sample\n",
    "features_df = pd.DataFrame([features_dict])\n",
    "\n",
    "# Predict using the model\n",
    "prediction = best_model.predict(features_df)\n",
    "\n",
    "# Output the result\n",
    "if prediction[0] == 1:\n",
    "    print(\"The executable is classified as malware.\")\n",
    "else:\n",
    "    print(\"The executable is classified as benign.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71747070-a965-413d-998e-450309b161c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
